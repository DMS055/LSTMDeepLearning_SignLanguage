{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8f323f",
   "metadata": {},
   "source": [
    "# Sign Language Recognition Using LSTM DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.5.0 tensorflow-gpu==2.5.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970be03",
   "metadata": {},
   "source": [
    "## Installing and importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a32a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28764d92",
   "metadata": {},
   "source": [
    "## Marking the keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "025241da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c4cecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_det(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    res = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71532c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def styled_landmarks(image, model):\n",
    "    # Face\n",
    "    mp_drawing.draw_landmarks(image, res.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)) \n",
    "    # Pose \n",
    "    mp_drawing.draw_landmarks(image, res.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)) \n",
    "    # Left hand\n",
    "    mp_drawing.draw_landmarks(image, res.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)) \n",
    "    # Right hand  \n",
    "    mp_drawing.draw_landmarks(image, res.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "# Setting the model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read capture\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Detect\n",
    "        image, res = mediapipe_det(frame, holistic)\n",
    "        print(res)\n",
    "        \n",
    "        # Draw\n",
    "        styled_landmarks(image, res)\n",
    "\n",
    "        cv.imshow(\"Camera Feed\", image)\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76d545",
   "metadata": {},
   "source": [
    "## Extracting the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c2470563",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = []\n",
    "for resV in res.pose_landmarks.landmark:\n",
    "    test = np.array([resV.x, resV.y, resV.z, resV.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed115736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(res):\n",
    "    # 33 * 4 = 33 landmarks, 4 values each (includes resV.visibility)\n",
    "    pose = np.array([[resV.x, resV.y, resV.z, resV.visibility] for rezV in res.pose_landmarks.landmark]).flatten() if res.pose_landmarks else np.zeros(132)\n",
    "    # 468 * 3 = 468 landmarks, 3 values each\n",
    "    face = np.array([[resV.x, resV.y, resV.z] for\n",
    "    lHand = np.array([[resV.x, resV.y, resV.z] for rezV in res.left_hand_landmarks.landmark]).flatten() if res.left_hand_landmarks else np.zeros(63)\n",
    "    rHand = np.array([[resV.x, resV.y, resV.z] for rezV in res.right_hand_landmarks.landmark]).flatten() if res.right_hand_landmarks else np.zeros(63) rezV in res.face_landmarks.landmark]).flatten() if res.face_landmarks else np.zeros(1404)\n",
    "    # 21 * 3 = 21 landmarks, 3 values each\n",
    "    return np.concatenate([pose, face, lHand, rHand])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c46bc",
   "metadata": {},
   "source": [
    "## Collection file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2f7a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data');\n",
    "actions = np.array(['hello', \"thanks\", \"i love you\"])\n",
    "\n",
    "# 30 seqences\n",
    "no_seq = 30\n",
    "\n",
    "# Every sequence 30 frames long\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2736de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for seq in range(no_seq):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(seq)))\n",
    "        except:\n",
    "            pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
